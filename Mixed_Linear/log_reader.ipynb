{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Details:\n",
      "   Epoch  Cost Time  Train Loss  Validation Loss  Test Loss\n",
      "0      1  38.031147    0.164008         0.185596   0.184927\n",
      "1      2  38.658848    0.153223         0.163479   0.151980\n",
      "2      3  38.440626    0.128649         0.140811   0.125382\n",
      "3      4  37.921396    0.118282         0.114316   0.116547\n",
      "4      5  38.984658    0.113287         0.107829   0.110105\n",
      "\n",
      "Summary Metrics:\n",
      "                  Metric      Value\n",
      "0        Average s/epoch  38.407335\n",
      "1       Final Train Loss   0.113287\n",
      "2  Final Validation Loss   0.107829\n",
      "3        Final Test Loss   0.110105\n",
      "4                    MSE        NaN\n",
      "5                    MAE        NaN\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from statistics import mean\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def parse_log(log_text):\n",
    "    # 각 epoch의 실행 시간과 loss 추출\n",
    "    epoch_pattern = r\"Epoch: (\\d+) cost time: (\\d+\\.\\d+).*?Train Loss: (\\d+\\.\\d+) Vali Loss: (\\d+\\.\\d+) Test Loss: (\\d+\\.\\d+)\"\n",
    "    epoch_matches = re.findall(epoch_pattern, log_text, re.DOTALL)\n",
    "    \n",
    "    data = []\n",
    "    for match in epoch_matches:\n",
    "        epoch = int(match[0])\n",
    "        cost_time = float(match[1])\n",
    "        train_loss = float(match[2])\n",
    "        vali_loss = float(match[3])\n",
    "        test_loss = float(match[4])\n",
    "        data.append([epoch, cost_time, train_loss, vali_loss, test_loss])\n",
    "    \n",
    "    # MSE와 MAE 추출\n",
    "    mse_mae_pattern = r\"mse: (\\d+\\.\\d+), mae: (\\d+\\.\\d+)\"\n",
    "    mse_mae_match = re.search(mse_mae_pattern, log_text)\n",
    "    if mse_mae_match:\n",
    "        mse = float(mse_mae_match.group(1))\n",
    "        mae = float(mse_mae_match.group(2))\n",
    "    else:\n",
    "        mse = mae = None\n",
    "    \n",
    "    return data, mse, mae\n",
    "\n",
    "def calculate_metrics(log_text):\n",
    "    data, mse, mae = parse_log(log_text)\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['Epoch', 'Cost Time', 'Train Loss', 'Validation Loss', 'Test Loss'])\n",
    "    \n",
    "    # 평균 s/epoch 계산\n",
    "    avg_s_per_epoch = df['Cost Time'].mean()\n",
    "    \n",
    "    # 최종 epoch의 loss 값들\n",
    "    final_epoch = df.iloc[-1]\n",
    "    \n",
    "    summary_df = pd.DataFrame({\n",
    "        'Metric': ['Average s/epoch', 'Final Train Loss', 'Final Validation Loss', 'Final Test Loss', 'MSE', 'MAE'],\n",
    "        'Value': [avg_s_per_epoch, final_epoch['Train Loss'], final_epoch['Validation Loss'], \n",
    "                  final_epoch['Test Loss'], mse, mae]\n",
    "    })\n",
    "    \n",
    "    return df, summary_df\n",
    "\n",
    "# 로그 텍스트를 문자열로 가정\n",
    "log_text = \"\"\"\n",
    "Args in experiment:\n",
    "Namespace(activation='gelu', batch_size=16, c_out=7, channels=8, checkpoints='./checkpoints/', d_ff=64, d_layers=1, d_model=16, data='custom', data_path='2022_2023_1_result.csv', dec_in=7, decomp_kernel_sizes=[25, 49], des='Exp', devices='0,1,2,3', distil=True, do_predict=True, dropout=0.1, e_layers=2, embed='timeF', embed_type=0, enc_in=8, factor=1, features='M', freq='5min', gpu=0, individual=False, is_training=1, itr=1, label_len=36, learning_rate=0.001, loss='mse', lradj='type1', model='Mixed_Linear2', model_id='2022_2023_1_result.csv_Mixed_Linear2_2022_2023_1_result.csv', moving_avg=30, n_heads=8, num_workers=10, output_attention=False, patience=2, pred_len=36, root_path='./Data_Final(실제 모델 입력데이터)/1_year', seq_len=96, target='현재수요(MW)', test_flop=False, train_epochs=5, train_only=False, use_amp=False, use_gpu=False, use_multi_gpu=False)\n",
    "Use CPU\n",
    ">>>>>>>start training : 2022_2023_1_result.csv_Mixed_Linear2_2022_2023_1_result.csv_Mixed_Linear2_custom_ftM_sl96_ll36_pl36_dm16_nh8_el2_dl1_df64_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "train 58735\n",
    "val 8375\n",
    "test 16784\n",
    "\titers: 100, epoch: 1 | loss: 0.2009769\n",
    "\tspeed: 0.2097s/iter; left time: 3827.9503s\n",
    "\titers: 200, epoch: 1 | loss: 0.1435711\n",
    "\tspeed: 0.0048s/iter; left time: 87.9830s\n",
    "\titers: 300, epoch: 1 | loss: 0.1161936\n",
    "\tspeed: 0.0047s/iter; left time: 84.2346s\n",
    "\titers: 400, epoch: 1 | loss: 0.1866358\n",
    "\tspeed: 0.0044s/iter; left time: 78.7262s\n",
    "\titers: 500, epoch: 1 | loss: 0.1250156\n",
    "\tspeed: 0.0045s/iter; left time: 80.7706s\n",
    "\titers: 600, epoch: 1 | loss: 0.1364736\n",
    "\tspeed: 0.0046s/iter; left time: 81.3138s\n",
    "\titers: 700, epoch: 1 | loss: 0.1389591\n",
    "\tspeed: 0.0068s/iter; left time: 120.0153s\n",
    "\titers: 800, epoch: 1 | loss: 0.1883078\n",
    "\tspeed: 0.0045s/iter; left time: 78.8724s\n",
    "\titers: 900, epoch: 1 | loss: 0.2471301\n",
    "\tspeed: 0.0044s/iter; left time: 76.3614s\n",
    "\titers: 1000, epoch: 1 | loss: 0.1759234\n",
    "\tspeed: 0.0047s/iter; left time: 82.2968s\n",
    "\titers: 1100, epoch: 1 | loss: 0.1252935\n",
    "\tspeed: 0.0048s/iter; left time: 83.2847s\n",
    "\titers: 1200, epoch: 1 | loss: 0.1264265\n",
    "\tspeed: 0.0046s/iter; left time: 78.1738s\n",
    "\titers: 1300, epoch: 1 | loss: 0.1112329\n",
    "\tspeed: 0.0044s/iter; left time: 74.8461s\n",
    "\titers: 1400, epoch: 1 | loss: 0.4558744\n",
    "\tspeed: 0.0042s/iter; left time: 70.9407s\n",
    "\titers: 1500, epoch: 1 | loss: 0.0844764\n",
    "\tspeed: 0.0044s/iter; left time: 74.6424s\n",
    "\titers: 1600, epoch: 1 | loss: 0.1308079\n",
    "\tspeed: 0.0045s/iter; left time: 75.7850s\n",
    "\titers: 1700, epoch: 1 | loss: 0.1482347\n",
    "\tspeed: 0.0043s/iter; left time: 71.9436s\n",
    "\titers: 1800, epoch: 1 | loss: 0.1515870\n",
    "\tspeed: 0.0046s/iter; left time: 75.3936s\n",
    "\titers: 1900, epoch: 1 | loss: 0.0961738\n",
    "\tspeed: 0.0046s/iter; left time: 75.0039s\n",
    "\titers: 2000, epoch: 1 | loss: 0.1459227\n",
    "\tspeed: 0.0048s/iter; left time: 78.7139s\n",
    "\titers: 2100, epoch: 1 | loss: 0.2379774\n",
    "\tspeed: 0.0048s/iter; left time: 78.4828s\n",
    "\titers: 2200, epoch: 1 | loss: 0.1456672\n",
    "\tspeed: 0.0048s/iter; left time: 78.0293s\n",
    "\titers: 2300, epoch: 1 | loss: 0.1162853\n",
    "\tspeed: 0.0050s/iter; left time: 79.5788s\n",
    "\titers: 2400, epoch: 1 | loss: 0.0923465\n",
    "\tspeed: 0.0044s/iter; left time: 70.9104s\n",
    "\titers: 2500, epoch: 1 | loss: 0.1736019\n",
    "\tspeed: 0.0043s/iter; left time: 68.8753s\n",
    "\titers: 2600, epoch: 1 | loss: 0.1170016\n",
    "\tspeed: 0.0045s/iter; left time: 70.3253s\n",
    "\titers: 2700, epoch: 1 | loss: 0.1281981\n",
    "\tspeed: 0.0045s/iter; left time: 70.5212s\n",
    "\titers: 2800, epoch: 1 | loss: 0.1574488\n",
    "\tspeed: 0.0048s/iter; left time: 75.0799s\n",
    "\titers: 2900, epoch: 1 | loss: 0.1380866\n",
    "\tspeed: 0.0046s/iter; left time: 70.6511s\n",
    "\titers: 3000, epoch: 1 | loss: 0.1335377\n",
    "\tspeed: 0.0043s/iter; left time: 66.7128s\n",
    "\titers: 3100, epoch: 1 | loss: 0.1505000\n",
    "\tspeed: 0.0045s/iter; left time: 69.2539s\n",
    "\titers: 3200, epoch: 1 | loss: 0.2200638\n",
    "\tspeed: 0.0043s/iter; left time: 65.7863s\n",
    "\titers: 3300, epoch: 1 | loss: 0.1290824\n",
    "\tspeed: 0.0044s/iter; left time: 66.8471s\n",
    "\titers: 3400, epoch: 1 | loss: 0.2204304\n",
    "\tspeed: 0.0044s/iter; left time: 65.4959s\n",
    "\titers: 3500, epoch: 1 | loss: 0.1391196\n",
    "\tspeed: 0.0043s/iter; left time: 64.2548s\n",
    "\titers: 3600, epoch: 1 | loss: 0.1931525\n",
    "\tspeed: 0.0046s/iter; left time: 67.8177s\n",
    "Epoch: 1 cost time: 38.03114700317383\n",
    "Epoch: 1, Steps: 3670 | Train Loss: 0.1640075 Vali Loss: 0.1855963 Test Loss: 0.1849273\n",
    "Validation loss decreased (inf --> 0.185596).  Saving model ...\n",
    "Updating learning rate to 0.001\n",
    "\titers: 100, epoch: 2 | loss: 0.2122322\n",
    "\tspeed: 0.6861s/iter; left time: 10003.5047s\n",
    "\titers: 200, epoch: 2 | loss: 0.2097276\n",
    "\tspeed: 0.0043s/iter; left time: 62.8134s\n",
    "\titers: 300, epoch: 2 | loss: 0.1334989\n",
    "\tspeed: 0.0045s/iter; left time: 65.0118s\n",
    "\titers: 400, epoch: 2 | loss: 0.1203873\n",
    "\tspeed: 0.0047s/iter; left time: 67.1127s\n",
    "\titers: 500, epoch: 2 | loss: 0.1254632\n",
    "\tspeed: 0.0048s/iter; left time: 67.9054s\n",
    "\titers: 600, epoch: 2 | loss: 0.1127032\n",
    "\tspeed: 0.0048s/iter; left time: 68.2470s\n",
    "\titers: 700, epoch: 2 | loss: 0.1340902\n",
    "\tspeed: 0.0047s/iter; left time: 66.4085s\n",
    "\titers: 800, epoch: 2 | loss: 0.2394587\n",
    "\tspeed: 0.0049s/iter; left time: 68.1214s\n",
    "\titers: 900, epoch: 2 | loss: 0.2299460\n",
    "\tspeed: 0.0046s/iter; left time: 63.5146s\n",
    "\titers: 1000, epoch: 2 | loss: 0.2155590\n",
    "\tspeed: 0.0043s/iter; left time: 59.2821s\n",
    "\titers: 1100, epoch: 2 | loss: 0.1379319\n",
    "\tspeed: 0.0045s/iter; left time: 61.3462s\n",
    "\titers: 1200, epoch: 2 | loss: 0.1451247\n",
    "\tspeed: 0.0044s/iter; left time: 59.3801s\n",
    "\titers: 1300, epoch: 2 | loss: 0.1451500\n",
    "\tspeed: 0.0044s/iter; left time: 58.9953s\n",
    "\titers: 1400, epoch: 2 | loss: 0.1359364\n",
    "\tspeed: 0.0045s/iter; left time: 59.4303s\n",
    "\titers: 1500, epoch: 2 | loss: 0.1308144\n",
    "\tspeed: 0.0043s/iter; left time: 56.9034s\n",
    "\titers: 1600, epoch: 2 | loss: 0.1124013\n",
    "\tspeed: 0.0049s/iter; left time: 63.5515s\n",
    "\titers: 1700, epoch: 2 | loss: 0.1596004\n",
    "\tspeed: 0.0046s/iter; left time: 60.0692s\n",
    "\titers: 1800, epoch: 2 | loss: 0.1582884\n",
    "\tspeed: 0.0045s/iter; left time: 57.8684s\n",
    "\titers: 1900, epoch: 2 | loss: 0.1154185\n",
    "\tspeed: 0.0045s/iter; left time: 57.9003s\n",
    "\titers: 2000, epoch: 2 | loss: 0.1693356\n",
    "\tspeed: 0.0047s/iter; left time: 59.1701s\n",
    "\titers: 2100, epoch: 2 | loss: 0.1115072\n",
    "\tspeed: 0.0045s/iter; left time: 57.0724s\n",
    "\titers: 2200, epoch: 2 | loss: 0.1090344\n",
    "\tspeed: 0.0044s/iter; left time: 55.2441s\n",
    "\titers: 2300, epoch: 2 | loss: 0.1288168\n",
    "\tspeed: 0.0043s/iter; left time: 52.6441s\n",
    "\titers: 2400, epoch: 2 | loss: 0.1439626\n",
    "\tspeed: 0.0044s/iter; left time: 54.0807s\n",
    "\titers: 2500, epoch: 2 | loss: 0.1111862\n",
    "\tspeed: 0.0050s/iter; left time: 60.6161s\n",
    "\titers: 2600, epoch: 2 | loss: 0.1115923\n",
    "\tspeed: 0.0049s/iter; left time: 59.1533s\n",
    "\titers: 2700, epoch: 2 | loss: 0.1155435\n",
    "\tspeed: 0.0046s/iter; left time: 55.6050s\n",
    "\titers: 2800, epoch: 2 | loss: 0.1297418\n",
    "\tspeed: 0.0043s/iter; left time: 51.2258s\n",
    "\titers: 2900, epoch: 2 | loss: 0.1809586\n",
    "\tspeed: 0.0048s/iter; left time: 56.7463s\n",
    "\titers: 3000, epoch: 2 | loss: 0.0952242\n",
    "\tspeed: 0.0058s/iter; left time: 67.6941s\n",
    "\titers: 3100, epoch: 2 | loss: 0.1700758\n",
    "\tspeed: 0.0061s/iter; left time: 70.5716s\n",
    "\titers: 3200, epoch: 2 | loss: 0.1624988\n",
    "\tspeed: 0.0048s/iter; left time: 55.2308s\n",
    "\titers: 3300, epoch: 2 | loss: 0.2646223\n",
    "\tspeed: 0.0050s/iter; left time: 56.6959s\n",
    "\titers: 3400, epoch: 2 | loss: 0.4132155\n",
    "\tspeed: 0.0051s/iter; left time: 57.6484s\n",
    "\titers: 3500, epoch: 2 | loss: 0.1805032\n",
    "\tspeed: 0.0068s/iter; left time: 76.1296s\n",
    "\titers: 3600, epoch: 2 | loss: 0.1427293\n",
    "\tspeed: 0.0050s/iter; left time: 55.4704s\n",
    "Epoch: 2 cost time: 38.65884828567505\n",
    "Epoch: 2, Steps: 3670 | Train Loss: 0.1532232 Vali Loss: 0.1634788 Test Loss: 0.1519804\n",
    "Validation loss decreased (0.185596 --> 0.163479).  Saving model ...\n",
    "Updating learning rate to 0.0005\n",
    "\titers: 100, epoch: 3 | loss: 0.0983781\n",
    "\tspeed: 0.6640s/iter; left time: 7244.7071s\n",
    "\titers: 200, epoch: 3 | loss: 0.1320294\n",
    "\tspeed: 0.0044s/iter; left time: 47.3219s\n",
    "\titers: 300, epoch: 3 | loss: 0.0971668\n",
    "\tspeed: 0.0044s/iter; left time: 47.1141s\n",
    "\titers: 400, epoch: 3 | loss: 0.1003175\n",
    "\tspeed: 0.0046s/iter; left time: 48.6191s\n",
    "\titers: 500, epoch: 3 | loss: 0.1276551\n",
    "\tspeed: 0.0048s/iter; left time: 50.2009s\n",
    "\titers: 600, epoch: 3 | loss: 0.1252530\n",
    "\tspeed: 0.0047s/iter; left time: 48.6223s\n",
    "\titers: 700, epoch: 3 | loss: 0.1057880\n",
    "\tspeed: 0.0046s/iter; left time: 47.3004s\n",
    "\titers: 800, epoch: 3 | loss: 0.1294073\n",
    "\tspeed: 0.0044s/iter; left time: 45.2620s\n",
    "\titers: 900, epoch: 3 | loss: 0.0885229\n",
    "\tspeed: 0.0044s/iter; left time: 44.8279s\n",
    "\titers: 1000, epoch: 3 | loss: 0.1162929\n",
    "\tspeed: 0.0049s/iter; left time: 48.7690s\n",
    "\titers: 1100, epoch: 3 | loss: 0.1139864\n",
    "\tspeed: 0.0046s/iter; left time: 45.3788s\n",
    "\titers: 1200, epoch: 3 | loss: 0.1160767\n",
    "\tspeed: 0.0048s/iter; left time: 47.0566s\n",
    "\titers: 1300, epoch: 3 | loss: 0.0970297\n",
    "\tspeed: 0.0043s/iter; left time: 41.8603s\n",
    "\titers: 1400, epoch: 3 | loss: 0.1508266\n",
    "\tspeed: 0.0068s/iter; left time: 65.7528s\n",
    "\titers: 1500, epoch: 3 | loss: 0.1230653\n",
    "\tspeed: 0.0051s/iter; left time: 48.0961s\n",
    "\titers: 1600, epoch: 3 | loss: 0.1125828\n",
    "\tspeed: 0.0049s/iter; left time: 45.6614s\n",
    "\titers: 1700, epoch: 3 | loss: 0.1154933\n",
    "\tspeed: 0.0051s/iter; left time: 47.3361s\n",
    "\titers: 1800, epoch: 3 | loss: 0.1375979\n",
    "\tspeed: 0.0066s/iter; left time: 60.7527s\n",
    "\titers: 1900, epoch: 3 | loss: 0.1230400\n",
    "\tspeed: 0.0056s/iter; left time: 51.4482s\n",
    "\titers: 2000, epoch: 3 | loss: 0.1372763\n",
    "\tspeed: 0.0046s/iter; left time: 41.7115s\n",
    "\titers: 2100, epoch: 3 | loss: 0.1329693\n",
    "\tspeed: 0.0046s/iter; left time: 41.2897s\n",
    "\titers: 2200, epoch: 3 | loss: 0.1032112\n",
    "\tspeed: 0.0046s/iter; left time: 40.7131s\n",
    "\titers: 2300, epoch: 3 | loss: 0.1335497\n",
    "\tspeed: 0.0049s/iter; left time: 43.0190s\n",
    "\titers: 2400, epoch: 3 | loss: 0.1336703\n",
    "\tspeed: 0.0045s/iter; left time: 38.4527s\n",
    "\titers: 2500, epoch: 3 | loss: 0.1138211\n",
    "\tspeed: 0.0045s/iter; left time: 38.0083s\n",
    "\titers: 2600, epoch: 3 | loss: 0.1502531\n",
    "\tspeed: 0.0044s/iter; left time: 36.6190s\n",
    "\titers: 2700, epoch: 3 | loss: 0.0894645\n",
    "\tspeed: 0.0048s/iter; left time: 39.5171s\n",
    "\titers: 2800, epoch: 3 | loss: 0.0728749\n",
    "\tspeed: 0.0044s/iter; left time: 35.9298s\n",
    "\titers: 2900, epoch: 3 | loss: 0.0949600\n",
    "\tspeed: 0.0043s/iter; left time: 35.0683s\n",
    "\titers: 3000, epoch: 3 | loss: 0.1209890\n",
    "\tspeed: 0.0045s/iter; left time: 36.2412s\n",
    "\titers: 3100, epoch: 3 | loss: 0.1493407\n",
    "\tspeed: 0.0048s/iter; left time: 37.6147s\n",
    "\titers: 3200, epoch: 3 | loss: 0.1402927\n",
    "\tspeed: 0.0047s/iter; left time: 36.9778s\n",
    "\titers: 3300, epoch: 3 | loss: 0.0931080\n",
    "\tspeed: 0.0043s/iter; left time: 33.5256s\n",
    "\titers: 3400, epoch: 3 | loss: 0.0905935\n",
    "\tspeed: 0.0046s/iter; left time: 35.0595s\n",
    "\titers: 3500, epoch: 3 | loss: 0.0854114\n",
    "\tspeed: 0.0046s/iter; left time: 34.5753s\n",
    "\titers: 3600, epoch: 3 | loss: 0.2271947\n",
    "\tspeed: 0.0045s/iter; left time: 33.2886s\n",
    "Epoch: 3 cost time: 38.44062614440918\n",
    "Epoch: 3, Steps: 3670 | Train Loss: 0.1286488 Vali Loss: 0.1408113 Test Loss: 0.1253821\n",
    "Validation loss decreased (0.163479 --> 0.140811).  Saving model ...\n",
    "Updating learning rate to 0.00025\n",
    "\titers: 100, epoch: 4 | loss: 0.0724688\n",
    "\tspeed: 0.6641s/iter; left time: 4808.7192s\n",
    "\titers: 200, epoch: 4 | loss: 0.0679200\n",
    "\tspeed: 0.0065s/iter; left time: 46.1366s\n",
    "\titers: 300, epoch: 4 | loss: 0.0943372\n",
    "\tspeed: 0.0050s/iter; left time: 35.2159s\n",
    "\titers: 400, epoch: 4 | loss: 0.0795509\n",
    "\tspeed: 0.0051s/iter; left time: 35.5746s\n",
    "\titers: 500, epoch: 4 | loss: 0.0794821\n",
    "\tspeed: 0.0053s/iter; left time: 36.2850s\n",
    "\titers: 600, epoch: 4 | loss: 0.1005720\n",
    "\tspeed: 0.0047s/iter; left time: 31.4521s\n",
    "\titers: 700, epoch: 4 | loss: 0.0916246\n",
    "\tspeed: 0.0046s/iter; left time: 30.4779s\n",
    "\titers: 800, epoch: 4 | loss: 0.1002940\n",
    "\tspeed: 0.0043s/iter; left time: 28.4107s\n",
    "\titers: 900, epoch: 4 | loss: 0.0991992\n",
    "\tspeed: 0.0043s/iter; left time: 27.5877s\n",
    "\titers: 1000, epoch: 4 | loss: 0.0922702\n",
    "\tspeed: 0.0044s/iter; left time: 27.6291s\n",
    "\titers: 1100, epoch: 4 | loss: 0.2485509\n",
    "\tspeed: 0.0045s/iter; left time: 27.9485s\n",
    "\titers: 1200, epoch: 4 | loss: 0.0713557\n",
    "\tspeed: 0.0045s/iter; left time: 27.5285s\n",
    "\titers: 1300, epoch: 4 | loss: 0.1162673\n",
    "\tspeed: 0.0048s/iter; left time: 28.8743s\n",
    "\titers: 1400, epoch: 4 | loss: 0.1656808\n",
    "\tspeed: 0.0045s/iter; left time: 26.6793s\n",
    "\titers: 1500, epoch: 4 | loss: 0.0699824\n",
    "\tspeed: 0.0044s/iter; left time: 25.8587s\n",
    "\titers: 1600, epoch: 4 | loss: 0.1049807\n",
    "\tspeed: 0.0047s/iter; left time: 27.0480s\n",
    "\titers: 1700, epoch: 4 | loss: 0.0889038\n",
    "\tspeed: 0.0043s/iter; left time: 24.0783s\n",
    "\titers: 1800, epoch: 4 | loss: 0.1232191\n",
    "\tspeed: 0.0046s/iter; left time: 25.3942s\n",
    "\titers: 1900, epoch: 4 | loss: 0.0740699\n",
    "\tspeed: 0.0044s/iter; left time: 23.9819s\n",
    "\titers: 2000, epoch: 4 | loss: 0.0987957\n",
    "\tspeed: 0.0046s/iter; left time: 24.4381s\n",
    "\titers: 2100, epoch: 4 | loss: 0.1178374\n",
    "\tspeed: 0.0049s/iter; left time: 25.7227s\n",
    "\titers: 2200, epoch: 4 | loss: 0.1042533\n",
    "\tspeed: 0.0046s/iter; left time: 23.6926s\n",
    "\titers: 2300, epoch: 4 | loss: 0.1061534\n",
    "\tspeed: 0.0046s/iter; left time: 23.0841s\n",
    "\titers: 2400, epoch: 4 | loss: 0.0997274\n",
    "\tspeed: 0.0044s/iter; left time: 21.5340s\n",
    "\titers: 2500, epoch: 4 | loss: 0.1949540\n",
    "\tspeed: 0.0045s/iter; left time: 21.9291s\n",
    "\titers: 2600, epoch: 4 | loss: 0.1058570\n",
    "\tspeed: 0.0044s/iter; left time: 20.7422s\n",
    "\titers: 2700, epoch: 4 | loss: 0.1062837\n",
    "\tspeed: 0.0046s/iter; left time: 21.5567s\n",
    "\titers: 2800, epoch: 4 | loss: 0.0993755\n",
    "\tspeed: 0.0046s/iter; left time: 21.0620s\n",
    "\titers: 2900, epoch: 4 | loss: 0.0868687\n",
    "\tspeed: 0.0047s/iter; left time: 20.9624s\n",
    "\titers: 3000, epoch: 4 | loss: 0.1243291\n",
    "\tspeed: 0.0049s/iter; left time: 21.1933s\n",
    "\titers: 3100, epoch: 4 | loss: 0.1234519\n",
    "\tspeed: 0.0047s/iter; left time: 20.0738s\n",
    "\titers: 3200, epoch: 4 | loss: 0.0870027\n",
    "\tspeed: 0.0044s/iter; left time: 18.3813s\n",
    "\titers: 3300, epoch: 4 | loss: 0.1152455\n",
    "\tspeed: 0.0044s/iter; left time: 17.8733s\n",
    "\titers: 3400, epoch: 4 | loss: 0.0921340\n",
    "\tspeed: 0.0047s/iter; left time: 18.4341s\n",
    "\titers: 3500, epoch: 4 | loss: 0.0891360\n",
    "\tspeed: 0.0049s/iter; left time: 18.8893s\n",
    "\titers: 3600, epoch: 4 | loss: 0.1235239\n",
    "\tspeed: 0.0047s/iter; left time: 17.4671s\n",
    "Epoch: 4 cost time: 37.921396255493164\n",
    "Epoch: 4, Steps: 3670 | Train Loss: 0.1182823 Vali Loss: 0.1143155 Test Loss: 0.1165471\n",
    "Validation loss decreased (0.140811 --> 0.114316).  Saving model ...\n",
    "Updating learning rate to 0.000125\n",
    "\titers: 100, epoch: 5 | loss: 0.1521723\n",
    "\tspeed: 0.6675s/iter; left time: 2383.5617s\n",
    "\titers: 200, epoch: 5 | loss: 0.0859374\n",
    "\tspeed: 0.0045s/iter; left time: 15.6883s\n",
    "\titers: 300, epoch: 5 | loss: 0.0800212\n",
    "\tspeed: 0.0044s/iter; left time: 14.8340s\n",
    "\titers: 400, epoch: 5 | loss: 0.0822010\n",
    "\tspeed: 0.0049s/iter; left time: 15.9486s\n",
    "\titers: 500, epoch: 5 | loss: 0.1632526\n",
    "\tspeed: 0.0048s/iter; left time: 15.2685s\n",
    "\titers: 600, epoch: 5 | loss: 0.0887114\n",
    "\tspeed: 0.0045s/iter; left time: 13.8366s\n",
    "\titers: 700, epoch: 5 | loss: 0.0935576\n",
    "\tspeed: 0.0046s/iter; left time: 13.6092s\n",
    "\titers: 800, epoch: 5 | loss: 0.0670833\n",
    "\tspeed: 0.0044s/iter; left time: 12.6548s\n",
    "\titers: 900, epoch: 5 | loss: 0.0826160\n",
    "\tspeed: 0.0048s/iter; left time: 13.2757s\n",
    "\titers: 1000, epoch: 5 | loss: 0.1110133\n",
    "\tspeed: 0.0044s/iter; left time: 11.6690s\n",
    "\titers: 1100, epoch: 5 | loss: 0.0873836\n",
    "\tspeed: 0.0043s/iter; left time: 11.1024s\n",
    "\titers: 1200, epoch: 5 | loss: 0.1182127\n",
    "\tspeed: 0.0046s/iter; left time: 11.2931s\n",
    "\titers: 1300, epoch: 5 | loss: 0.0740035\n",
    "\tspeed: 0.0047s/iter; left time: 11.1979s\n",
    "\titers: 1400, epoch: 5 | loss: 0.1164241\n",
    "\tspeed: 0.0046s/iter; left time: 10.5112s\n",
    "\titers: 1500, epoch: 5 | loss: 0.0843810\n",
    "\tspeed: 0.0046s/iter; left time: 10.0266s\n",
    "\titers: 1600, epoch: 5 | loss: 0.0911696\n",
    "\tspeed: 0.0048s/iter; left time: 9.8850s\n",
    "\titers: 1700, epoch: 5 | loss: 0.0788434\n",
    "\tspeed: 0.0049s/iter; left time: 9.6788s\n",
    "\titers: 1800, epoch: 5 | loss: 0.1151721\n",
    "\tspeed: 0.0047s/iter; left time: 8.8523s\n",
    "\titers: 1900, epoch: 5 | loss: 0.0970933\n",
    "\tspeed: 0.0044s/iter; left time: 7.7193s\n",
    "\titers: 2000, epoch: 5 | loss: 0.0909674\n",
    "\tspeed: 0.0049s/iter; left time: 8.1909s\n",
    "\titers: 2100, epoch: 5 | loss: 0.7622734\n",
    "\tspeed: 0.0048s/iter; left time: 7.5386s\n",
    "\titers: 2200, epoch: 5 | loss: 0.1024953\n",
    "\tspeed: 0.0047s/iter; left time: 6.8716s\n",
    "\titers: 2300, epoch: 5 | loss: 0.0936008\n",
    "\tspeed: 0.0046s/iter; left time: 6.2859s\n",
    "\titers: 2400, epoch: 5 | loss: 0.1026615\n",
    "\tspeed: 0.0047s/iter; left time: 5.9334s\n",
    "\titers: 2500, epoch: 5 | loss: 0.0636899\n",
    "\tspeed: 0.0054s/iter; left time: 6.2748s\n",
    "\titers: 2600, epoch: 5 | loss: 0.1203504\n",
    "\tspeed: 0.0050s/iter; left time: 5.3933s\n",
    "\titers: 2700, epoch: 5 | loss: 0.2008623\n",
    "\tspeed: 0.0053s/iter; left time: 5.1585s\n",
    "\titers: 2800, epoch: 5 | loss: 0.1193424\n",
    "\tspeed: 0.0053s/iter; left time: 4.6272s\n",
    "\titers: 2900, epoch: 5 | loss: 0.1532698\n",
    "\tspeed: 0.0055s/iter; left time: 4.2467s\n",
    "\titers: 3000, epoch: 5 | loss: 0.1106170\n",
    "\tspeed: 0.0049s/iter; left time: 3.2743s\n",
    "\titers: 3100, epoch: 5 | loss: 0.0777549\n",
    "\tspeed: 0.0051s/iter; left time: 2.8922s\n",
    "\titers: 3200, epoch: 5 | loss: 0.1010087\n",
    "\tspeed: 0.0066s/iter; left time: 3.1312s\n",
    "\titers: 3300, epoch: 5 | loss: 0.1060878\n",
    "\tspeed: 0.0046s/iter; left time: 1.7165s\n",
    "\titers: 3400, epoch: 5 | loss: 0.1024142\n",
    "\tspeed: 0.0051s/iter; left time: 1.3832s\n",
    "\titers: 3500, epoch: 5 | loss: 0.1303425\n",
    "\tspeed: 0.0046s/iter; left time: 0.7783s\n",
    "\titers: 3600, epoch: 5 | loss: 0.0975262\n",
    "\tspeed: 0.0044s/iter; left time: 0.3153s\n",
    "Epoch: 5 cost time: 38.984657764434814\n",
    "Epoch: 5, Steps: 3670 | Train Loss: 0.1132868 Vali Loss: 0.1078294 Test Loss: 0.1101055\n",
    "Validation loss decreased (0.114316 --> 0.107829).  Saving model ...\n",
    "Updating learning rate to 6.25e-05\n",
    ">>>>>>>testing : 2022_2023_1_result.csv_Mixed_Linear2_2022_2023_1_result.csv_Mixed_Linear2_custom_ftM_sl96_ll36_pl36_dm16_nh8_el2_dl1_df64_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "test 16784\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "epoch_df, summary_df = calculate_metrics(log_text)\n",
    "\n",
    "print(\"Epoch Details:\")\n",
    "print(epoch_df)\n",
    "print(\"\\nSummary Metrics:\")\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_TSF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
